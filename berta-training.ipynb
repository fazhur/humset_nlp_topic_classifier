{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-18T22:13:31.433647Z",
     "iopub.status.busy": "2024-12-18T22:13:31.433363Z",
     "iopub.status.idle": "2024-12-18T22:13:52.144559Z",
     "shell.execute_reply": "2024-12-18T22:13:52.143704Z",
     "shell.execute_reply.started": "2024-12-18T22:13:31.433614Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T22:13:52.146542Z",
     "iopub.status.busy": "2024-12-18T22:13:52.146038Z",
     "iopub.status.idle": "2024-12-18T22:14:03.882868Z",
     "shell.execute_reply": "2024-12-18T22:14:03.881546Z",
     "shell.execute_reply.started": "2024-12-18T22:13:52.146504Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! pip install -q evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T22:14:03.885121Z",
     "iopub.status.busy": "2024-12-18T22:14:03.884595Z",
     "iopub.status.idle": "2024-12-18T22:14:05.206987Z",
     "shell.execute_reply": "2024-12-18T22:14:05.206028Z",
     "shell.execute_reply.started": "2024-12-18T22:14:03.885053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T22:14:05.210139Z",
     "iopub.status.busy": "2024-12-18T22:14:05.209165Z",
     "iopub.status.idle": "2024-12-18T22:14:05.214743Z",
     "shell.execute_reply": "2024-12-18T22:14:05.213617Z",
     "shell.execute_reply.started": "2024-12-18T22:14:05.210106Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PATH = \"/kaggle/input/dataset-topics/\"\n",
    "data_name = \"humset_bias_train_en_normalized.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T22:14:05.216712Z",
     "iopub.status.busy": "2024-12-18T22:14:05.216248Z",
     "iopub.status.idle": "2024-12-18T22:14:06.198988Z",
     "shell.execute_reply": "2024-12-18T22:14:06.197949Z",
     "shell.execute_reply.started": "2024-12-18T22:14:05.216667Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>subpillars</th>\n",
       "      <th>subpillars_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293791</td>\n",
       "      <td>Highly vulnerable regions like Africa need at ...</td>\n",
       "      <td>[Context-&gt;Economy, Context-&gt;Environment]</td>\n",
       "      <td>Context-&gt;Economy~Context-&gt;Environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169537</td>\n",
       "      <td>The deterioration of the security situation ha...</td>\n",
       "      <td>[Displacement-&gt;Push factors, Displacement-&gt;Typ...</td>\n",
       "      <td>Displacement-&gt;Push factors~Displacement-&gt;Type/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155848</td>\n",
       "      <td>To date, UNHCR and its partner the Fondation H...</td>\n",
       "      <td>[Information and communication-&gt;Communication ...</td>\n",
       "      <td>Information and communication-&gt;Communication m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>158303</td>\n",
       "      <td>\"We're seeing an alarming deterioration in foo...</td>\n",
       "      <td>[Humanitarian conditions-&gt;Living standards, Im...</td>\n",
       "      <td>Humanitarian conditions-&gt;Living standards~Impa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>337197</td>\n",
       "      <td>In January and February 2021, UNICEF and its p...</td>\n",
       "      <td>[Capacities &amp; response-&gt;International response...</td>\n",
       "      <td>Capacities &amp; response-&gt;International response~...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  \\\n",
       "0  293791  Highly vulnerable regions like Africa need at ...   \n",
       "1  169537  The deterioration of the security situation ha...   \n",
       "2  155848  To date, UNHCR and its partner the Fondation H...   \n",
       "3  158303  \"We're seeing an alarming deterioration in foo...   \n",
       "4  337197  In January and February 2021, UNICEF and its p...   \n",
       "\n",
       "                                          subpillars  \\\n",
       "0           [Context->Economy, Context->Environment]   \n",
       "1  [Displacement->Push factors, Displacement->Typ...   \n",
       "2  [Information and communication->Communication ...   \n",
       "3  [Humanitarian conditions->Living standards, Im...   \n",
       "4  [Capacities & response->International response...   \n",
       "\n",
       "                                   subpillars_labels  \n",
       "0              Context->Economy~Context->Environment  \n",
       "1  Displacement->Push factors~Displacement->Type/...  \n",
       "2  Information and communication->Communication m...  \n",
       "3  Humanitarian conditions->Living standards~Impa...  \n",
       "4  Capacities & response->International response~...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(PATH + data_name, lines=True)\n",
    "\n",
    "data['subpillars'] = data['subpillars'].apply(lambda x: [\"No-topics\"] if len(x) == 0 else x)\n",
    "data['subpillars_labels'] = data['subpillars'].apply(lambda x: \"~\".join(x))\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T22:14:06.201162Z",
     "iopub.status.busy": "2024-12-18T22:14:06.200419Z",
     "iopub.status.idle": "2024-12-18T22:14:06.221317Z",
     "shell.execute_reply": "2024-12-18T22:14:06.220364Z",
     "shell.execute_reply.started": "2024-12-18T22:14:06.201125Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = data.sample(frac=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T22:14:06.223633Z",
     "iopub.status.busy": "2024-12-18T22:14:06.222773Z",
     "iopub.status.idle": "2024-12-18T22:14:06.230105Z",
     "shell.execute_reply": "2024-12-18T22:14:06.229108Z",
     "shell.execute_reply.started": "2024-12-18T22:14:06.223568Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28568"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T22:14:06.231727Z",
     "iopub.status.busy": "2024-12-18T22:14:06.231374Z",
     "iopub.status.idle": "2024-12-18T22:14:06.267001Z",
     "shell.execute_reply": "2024-12-18T22:14:06.265941Z",
     "shell.execute_reply.started": "2024-12-18T22:14:06.231686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_topics = set(topic for topics in data['subpillars'] for topic in topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T22:14:06.268661Z",
     "iopub.status.busy": "2024-12-18T22:14:06.268343Z",
     "iopub.status.idle": "2024-12-18T22:14:06.343437Z",
     "shell.execute_reply": "2024-12-18T22:14:06.342373Z",
     "shell.execute_reply.started": "2024-12-18T22:14:06.268631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_labels = list(set(label for sublist in data[\"subpillars\"] for label in sublist))\n",
    "label_to_index = {label: idx for idx, label in enumerate(all_labels)}\n",
    "num_labels = len(all_labels)\n",
    "\n",
    "def encode_labels(subpillars):\n",
    "    \"\"\"Generate a multi-hot vector with 1s for the existing labels and 0s elsewhere.\"\"\"\n",
    "    multi_hot = [0.0] * num_labels\n",
    "    for label in subpillars:\n",
    "        multi_hot[label_to_index[label]] = 1.0\n",
    "    return multi_hot\n",
    "\n",
    "data[\"labels\"] = data[\"subpillars\"].apply(encode_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T22:14:06.346296Z",
     "iopub.status.busy": "2024-12-18T22:14:06.345972Z",
     "iopub.status.idle": "2024-12-18T22:14:06.353774Z",
     "shell.execute_reply": "2024-12-18T22:14:06.352704Z",
     "shell.execute_reply.started": "2024-12-18T22:14:06.346266Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Shock/event->Hazard & threats': 0,\n",
       " 'At risk->Risk and vulnerabilities': 1,\n",
       " 'Priority needs->Expressed by humanitarian staff': 2,\n",
       " 'Humanitarian conditions->Number of people in need': 3,\n",
       " 'Covid-19->Restriction measures': 4,\n",
       " 'Shock/event->Underlying/aggravating factors': 5,\n",
       " 'Displacement->Push factors': 6,\n",
       " 'Humanitarian conditions->Coping mechanisms': 7,\n",
       " 'Context->Security & stability': 8,\n",
       " 'Context->Socio cultural': 9,\n",
       " 'Casualties->Injured': 10,\n",
       " 'Covid-19->Prevention campaign': 11,\n",
       " 'Priority interventions->Expressed by humanitarian staff': 12,\n",
       " 'Context->Economy': 13,\n",
       " 'Displacement->Type/numbers/movements': 14,\n",
       " 'Covid-19->Vaccination': 15,\n",
       " 'Information and communication->Communication means and preferences': 16,\n",
       " 'Context->Demography': 17,\n",
       " 'Casualties->Dead': 18,\n",
       " 'Capacities & response->People reached/response gaps': 19,\n",
       " 'Capacities & response->National response': 20,\n",
       " 'Humanitarian conditions->Living standards': 21,\n",
       " 'Priority needs->Expressed by population': 22,\n",
       " 'Impact->Impact on people': 23,\n",
       " 'Impact->Number of people affected': 24,\n",
       " 'Covid-19->Testing': 25,\n",
       " 'Information and communication->Knowledge and info gaps (pop)': 26,\n",
       " 'Context->Legal & policy': 27,\n",
       " 'Context->Environment': 28,\n",
       " 'Humanitarian conditions->Physical and mental well being': 29,\n",
       " 'Capacities & response->International response': 30,\n",
       " 'Context->Politics': 31,\n",
       " 'Impact->Driver/aggravating factors': 32,\n",
       " 'Information and communication->Knowledge and info gaps (hum)': 33,\n",
       " 'Covid-19->Cases': 34,\n",
       " 'Humanitarian access->Relief to population': 35,\n",
       " 'Impact->Impact on systems, services and networks': 36,\n",
       " 'Covid-19->Deaths': 37,\n",
       " 'Humanitarian access->Physical constraints': 38,\n",
       " 'Shock/event->Type and characteristics': 39}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T22:14:06.355336Z",
     "iopub.status.busy": "2024-12-18T22:14:06.355019Z",
     "iopub.status.idle": "2024-12-18T22:14:06.399443Z",
     "shell.execute_reply": "2024-12-18T22:14:06.398321Z",
     "shell.execute_reply.started": "2024-12-18T22:14:06.355307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "val_data = val_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T22:14:06.401275Z",
     "iopub.status.busy": "2024-12-18T22:14:06.400873Z",
     "iopub.status.idle": "2024-12-18T22:14:06.408931Z",
     "shell.execute_reply": "2024-12-18T22:14:06.407767Z",
     "shell.execute_reply.started": "2024-12-18T22:14:06.401242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.data.loc[index, \"text\"]\n",
    "        labels = self.data.loc[index, \"labels\"]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T22:14:06.410738Z",
     "iopub.status.busy": "2024-12-18T22:14:06.410383Z",
     "iopub.status.idle": "2024-12-18T22:14:06.905130Z",
     "shell.execute_reply": "2024-12-18T22:14:06.904126Z",
     "shell.execute_reply.started": "2024-12-18T22:14:06.410708Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = \"/kaggle/input/berta/transformers/default/1\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(all_topics), problem_type=\"multi_label_classification\")\n",
    "max_len = 512\n",
    "epoch_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T22:14:06.907012Z",
     "iopub.status.busy": "2024-12-18T22:14:06.906518Z",
     "iopub.status.idle": "2024-12-18T22:14:06.913441Z",
     "shell.execute_reply": "2024-12-18T22:14:06.912358Z",
     "shell.execute_reply.started": "2024-12-18T22:14:06.906958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_train = TextDataset(train_data, tokenizer, max_len)\n",
    "data_loader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "\n",
    "dataset_val = TextDataset(val_data, tokenizer, max_len)\n",
    "data_loader_val = DataLoader(dataset_val, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:28:55.394363Z",
     "iopub.status.busy": "2024-12-18T23:28:55.393965Z",
     "iopub.status.idle": "2024-12-18T23:28:56.403136Z",
     "shell.execute_reply": "2024-12-18T23:28:56.402355Z",
     "shell.execute_reply.started": "2024-12-18T23:28:55.394334Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "num_training_steps = len(data_loader_train) * 2\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = sigmoid(predictions)\n",
    "    predictions = (predictions > 0.5).astype(int).reshape(-1)\n",
    "    return clf_metrics.compute(predictions=predictions, references=labels.astype(int).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T23:28:58.600828Z",
     "iopub.status.busy": "2024-12-18T23:28:58.600483Z",
     "iopub.status.idle": "2024-12-19T00:03:39.196978Z",
     "shell.execute_reply": "2024-12-19T00:03:39.195641Z",
     "shell.execute_reply.started": "2024-12-18T23:28:58.600798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(epoch_num):\n",
    "    print(f\"Starting epoch {epoch+1}/{epoch_num}\")\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(data_loader_train, desc=\"Training\", leave=False):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(data_loader_train)\n",
    "    print(f\"Epoch {epoch+1} Training Loss: {avg_train_loss}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader_val, desc=\"Validation\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = loss_fn(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            all_predictions.append(logits.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(data_loader_val)\n",
    "    print(f\"Epoch {epoch+1} Validation Loss: {avg_val_loss}\")\n",
    "\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    metrics = compute_metrics((all_predictions, all_labels))\n",
    "    print(f\"Epoch {epoch+1} Metrics: {metrics}\")\n",
    "\n",
    "    model.save_pretrained(f\"./bert_multilabel_classification_model_epoch_{epoch+1}\")\n",
    "    tokenizer.save_pretrained(f\"./bert_multilabel_classification_model_epoch_{epoch+1}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6325097,
     "sourceId": 10239415,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 195528,
     "modelInstanceId": 173193,
     "sourceId": 202995,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
